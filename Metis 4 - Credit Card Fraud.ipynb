{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29574a76",
   "metadata": {},
   "source": [
    "# Libraries / Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0640dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're pitching this to banks companies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import time\n",
    "from time import sleep, time\n",
    "from timeit import timeit\n",
    "\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "\n",
    "import imblearn\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90722d",
   "metadata": {},
   "source": [
    "# General-use Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9e0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads csv file and returns X and y arrays/dataframes\n",
    "def read_dataset(as_numpy_array=True):\n",
    "    read_data_=pd.read_csv(\"creditcard.csv\")\n",
    "    X=read_data_.drop(['Class'],axis=1)\n",
    "    y=read_data_['Class']\n",
    "    del read_data_\n",
    "    if as_numpy_array:\n",
    "        return(np.array(X),np.array(y))\n",
    "    else:\n",
    "        return(X,y)\n",
    "    \n",
    "def read_dataset_reg(as_numpy_array=True):\n",
    "    read_data_=pd.read_csv(\"creditcard.csv\")\n",
    "    scaler = StandardScaler()\n",
    "    y=read_data_['Class']\n",
    "    read_data_.drop(['Class'],axis=1,inplace=True)\n",
    "    X = scaler.fit_transform(read_data_)\n",
    "\n",
    "    del read_data_\n",
    "    if as_numpy_array:\n",
    "        return(np.array(X),np.array(y))\n",
    "    else:\n",
    "        return(X,y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd98f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring Models from Class. Eval. Pair\n",
    "def accuracy(actuals, preds):\n",
    "    truth_matrix=actuals==preds\n",
    "    success=0\n",
    "    for item in truth_matrix:\n",
    "        if item:\n",
    "            success+=1\n",
    "    return(success/len(actuals))\n",
    "\n",
    "\n",
    "def precision(actuals, preds):\n",
    "    true_positive=0\n",
    "    false_positive=0\n",
    "    for i in range(len(actuals)):\n",
    "        if not actuals[i] and preds[i]:\n",
    "            false_positive+=1\n",
    "        if actuals[i] and preds[i]:\n",
    "            true_positive+=1\n",
    "            \n",
    "    if true_positive+false_positive==0:\n",
    "        return('error: divide by 0')\n",
    "    return(true_positive/(true_positive+false_positive))\n",
    "    \n",
    "    \n",
    "def recall(actuals, preds):\n",
    "    true_positive=0\n",
    "    false_negative=0\n",
    "    for i in range(len(actuals)):\n",
    "        if actuals[i] and not preds[i]:\n",
    "            false_negative+=1\n",
    "        if actuals[i] and preds[i]:\n",
    "            true_positive+=1\n",
    "            \n",
    "    if true_positive+false_negative==0:\n",
    "        return('error: divide by 0')\n",
    "    return(true_positive/(true_positive+false_negative))\n",
    "\n",
    "\n",
    "def f1(actuals, preds):\n",
    "    if precision(actuals,preds)=='error: divide by 0':\n",
    "        return('precision error: divide by 0')\n",
    "    if recall(actuals,preds)=='error: divide by 0':\n",
    "        return('recall error: divide by 0')\n",
    "    \n",
    "    mult=precision(actuals,preds)*recall(actuals,preds)\n",
    "    add=precision(actuals,preds)+recall(actuals,preds)\n",
    "    return(2*mult/add)\n",
    "\n",
    "def f1v2(precision, recall):\n",
    "    mult=precision*recall\n",
    "    add=precision+recall\n",
    "    return(2*mult/add)\n",
    "    \n",
    "def score(actuals, preds):\n",
    "    \n",
    "    return({\"accuracy\":accuracy(actuals, preds), \"precision\":precision(actuals, preds), \"recall\":recall(actuals, preds), \"f1\":f1(actuals, preds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed23230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currency value in Euros, but the model can be used for any currency/location\n",
    "\n",
    "TotalFraudCost=958*1e6\n",
    "TotalFraudCards=11.29*1e6\n",
    "\n",
    "AvgFraudLoss=TotalFraudCost/TotalFraudCards\n",
    "AvgFraudLoss\n",
    "\n",
    "#Cost of investigation\n",
    "CpBase=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffee063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of simplicity, we assume that customers do not churn due to fraud,\n",
    "# but we'll include the variables in the cost function for ease of re-fitting models.\n",
    "\n",
    "#Placeholder variables:\n",
    "#Chance of churn becuase of False Neg P(Cn)\n",
    "PCn=0.00\n",
    "#Chance of churn becuase of False Pos = P(Cp)\n",
    "PCp=0.00\n",
    "#Cost of replacing customer CR\n",
    "CR=0\n",
    "\n",
    "Cn=CR*PCn\n",
    "Cp=CR*PCp\n",
    "\n",
    "\n",
    "#Calculates costs per transaction\n",
    "def costs(actuals, preds, f_pos_cost=CpBase+Cp,f_neg_cost=AvgFraudLoss+Cn):\n",
    "    pred_positive=0\n",
    "    false_negative=0\n",
    "    \n",
    "    for i in range(len(actuals)):\n",
    "        #We have to pay for investigations regardless of whether transaction is really fraudulent\n",
    "        if preds[i]:\n",
    "            pred_positive+=1\n",
    "        #We lose money only if fraud not intercepted\n",
    "        if actuals[i] and not preds[i]:\n",
    "            false_negative+=1\n",
    "    \n",
    "    total_cost=f_pos_cost*pred_positive+f_neg_cost*false_negative\n",
    "    return(total_cost/len(actuals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3d9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline costs for naive models\n",
    "y=read_dataset()[1]\n",
    "all_legit_costs=costs(y,np.zeros(len(y)))\n",
    "all_fraud_costs=costs(y,np.ones(len(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e3d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost per Transaction if all marked legitimate: €0.14658381170363086\n",
      "Cost per Transaction if all marked fraudulent: €6.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Cost per Transaction if all marked legitimate: €{all_legit_costs}')\n",
    "print(f'Cost per Transaction if all marked fraudulent: €{all_fraud_costs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59fd07",
   "metadata": {},
   "source": [
    "# Prepare Dataset for out-of-box models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c08b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data, split it 60/40 Train/Test\n",
    "\n",
    "Xy=read_dataset()\n",
    "X_train, X_test, y_train, y_test=train_test_split(Xy[0],Xy[1],test_size=0.2,random_state=hash(\"Server-Clearing Market Gardener\")%(2**32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71959e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraud_count=(y_train==1).sum()\n",
    "test_fraud_count=(y_test==1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbcfd6d",
   "metadata": {},
   "source": [
    "# So I think the metric we're focusing on most is Cost, not any traditional scoring method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f6abdb",
   "metadata": {},
   "source": [
    "# Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ee7a2",
   "metadata": {},
   "source": [
    "### Baseline: Out-of-box Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "de94668b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'throw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'throw' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "throw(\"Throw-wall to prevent accidental loss of progress\")\n",
    "\n",
    "logreg_oob=LogisticRegression(max_iter=1000)\n",
    "\n",
    "print('Fitting...',end='')\n",
    "logreg_oob.fit(X_train, y_train)\n",
    "\n",
    "print('Scoring Recall...',end='')\n",
    "oob_recall=cross_val_score(logreg_oob, X_train, y_train, cv=5, scoring=\"recall\")\n",
    "print('Scoring Precision...',end='')\n",
    "oob_precision=cross_val_score(logreg_oob, X_train, y_train, cv=5, scoring=\"precision\")\n",
    "print('Predicting Values...')\n",
    "logreg_oob_preds=logreg_oob.predict(X_test)\n",
    "\n",
    "print(f'precision={oob_precision.mean()}\\nrecall={oob_recall.mean()}\\nf1={f1v2(oob_precision.mean(), oob_recall.mean())}')\n",
    "\n",
    "print('Predicting Costs...')\n",
    "logreg_oob_costs=costs(y_test,logreg_oob_preds)\n",
    "print(f'Cost of baseline model: €{logreg_oob_costs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "afb45d6b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg_oob_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mk/f8dyn74n2kb1xh98q8xhy3d80000gn/T/ipykernel_65701/1142282572.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcosts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogreg_oob_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Baseline LogReg cost: €0.05034773854644103\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg_oob_preds' is not defined"
     ]
    }
   ],
   "source": [
    "costs(y_test,logreg_oob_preds)\n",
    "#Baseline LogReg cost: €0.05034773854644103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31f934",
   "metadata": {},
   "source": [
    "### Ok, not terrible, not great. That's an okay baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c410f",
   "metadata": {},
   "source": [
    "#### Ok after trying an out-of-box baseline I think KNN's going to take way too long to create a proper model let's just stick with logistic regression for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f85e28",
   "metadata": {},
   "source": [
    "# Fine-Tune Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac485c49",
   "metadata": {},
   "source": [
    "### Attempt 1: Undersample Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9cd2e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "RERUN_US_LOGREG=True\n",
    "\n",
    "if RERUN_US_LOGREG:\n",
    "    \n",
    "    us_recall={}\n",
    "    us_precision={}\n",
    "    us_f1={}\n",
    "\n",
    "    us_cost={}\n",
    "    for neg_pos_ratio in range(95,116,1):\n",
    "\n",
    "        \n",
    "\n",
    "        print(neg_pos_ratio, end='_')\n",
    "        \n",
    "        us_precision_temp=0\n",
    "        us_recall_temp=0\n",
    "        us_f1_temp=0\n",
    "        logreg_us_costs=0\n",
    "        \n",
    "        for attempts in range(0,10):\n",
    "            X_tr, X_val, y_tr, y_val=train_test_split(X_train,y_train,test_size=0.25,random_state=(hash(\"Kris Get The Banana Potassium\")*attempts)%(2**32))\n",
    "            \n",
    "            n_pos = np.sum(y_tr == 1)\n",
    "            n_neg = np.sum(y_tr == 0)\n",
    "            sampling_ratio = {1 : n_pos, 0 : n_pos*neg_pos_ratio}\n",
    "            \n",
    "            RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha sands uednertal\")*attempts)%(2**32))\n",
    "            X_tr_rs, y_tr_rs = RUS.fit_resample(X_tr, y_tr)\n",
    "\n",
    "            logreg_us=LogisticRegression(max_iter=1000)\n",
    "            logreg_us.fit(X_tr_rs, y_tr_rs)\n",
    "            \n",
    "            #Minimizing cost is my priority - model scoring is secondary\n",
    "            \n",
    "            #print('p_',end='')\n",
    "            #us_precision_temp+=cross_val_score(logreg_us, X_tr_rs, y_tr_rs, cv=5, scoring=\"precision\")    \n",
    "            #print('r_',end='')\n",
    "            #us_recall_temp+=cross_val_score(logreg_us, X_tr_rs, y_tr_rs, cv=5, scoring=\"recall\")\n",
    "            #print('f_',end='')\n",
    "            #us_f1_temp+=cross_val_score(logreg_us, X_tr_rs, y_tr_rs, cv=5, scoring=\"f1\")\n",
    "            \n",
    "            logreg_us_preds=logreg_us.predict(X_val)\n",
    "            logreg_us_costs+=costs(y_val,logreg_us_preds)\n",
    "        \n",
    "        us_recall[neg_pos_ratio]=us_recall_temp/(attempts+1)\n",
    "        us_precision[neg_pos_ratio]=us_precision_temp/(attempts+1)\n",
    "        us_f1[neg_pos_ratio]=us_f1_temp/(attempts+1)\n",
    "\n",
    "        us_cost[neg_pos_ratio]=logreg_us_costs/(attempts+1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b773cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating by 10s: Most efficient sampling ratio is ~1:110\n",
    "# Best undersampling is 1-107 with €0.0421/transaction with validation data (€0.0345 w/ test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbbd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Increasing data ratio above 40-1 doesn't seem to have much effect on f1, recall, prec...\n",
    "#okay precision gets affected way too much by random chance to make much of a prediction\n",
    "#let's just say ~30-40 is the optimal data ratio for scoring\n",
    "\n",
    "#print('Recall')\n",
    "#for item in us_recall:\n",
    "#    print (item, us_recall[item].mean())\n",
    "\n",
    "# print('Precision')\n",
    "# for item in us_precision:\n",
    "#     print (item, us_precision[item].mean())\n",
    "\n",
    "# print('F1')\n",
    "# for item in us_f1:\n",
    "#     print (item, us_f1[item].mean())\n",
    "\n",
    "print('Cost')\n",
    "for item in us_cost:\n",
    "    print (item, us_cost[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c6abc47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05391408360161417"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*107}\n",
    "\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha sands uednertal\"))%(2**32))\n",
    "\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "logreg_us=LogisticRegression(max_iter=1000)\n",
    "logreg_us.fit(X_tr_rs, y_tr_rs)\n",
    "logreg_us_preds=logreg_us.predict(X_test)\n",
    "costs(y_test,logreg_us_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "38a96bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9986833327481479,\n",
       " 'precision': 0.6307692307692307,\n",
       " 'recall': 0.7522935779816514,\n",
       " 'f1': 0.686192468619247}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(y_test,logreg_us_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee707cc",
   "metadata": {},
   "source": [
    "### Attempt 2: Adjust Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c69ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Fine-tuning weighting hyperparameter\n",
    "\n",
    "RERUN_CW_LOGREG=True\n",
    "\n",
    "if RERUN_CW_LOGREG:\n",
    "\n",
    "    w_recall={}\n",
    "    w_precision={}\n",
    "    w_f1={}\n",
    "\n",
    "    w_cost={}\n",
    "    \n",
    "    #Splitting data train-validation-test 60-20-20\n",
    "    X_tr, X_test, y_tr, y_test=train_test_split(Xy[0],Xy[1],test_size=0.2,random_state=hash(\"HEY EVERY! IT'S ME!\")%(2**32-1))\n",
    "    for neg_pos_ratio in range(70,121,5):\n",
    "        logreg_w_costs=0\n",
    "        print(neg_pos_ratio, end=',')\n",
    "        for attempt in range(0,10):\n",
    "            print(attempt, end='_')\n",
    "            X_train, X_val, y_train, y_val=train_test_split(X_tr,y_tr,test_size=0.25,random_state=hash(\"SPAMT    SPAMTON G. SPAMTON\")*attempt%(2**32-1))\n",
    "            n_pos = np.sum(y_train == 1)\n",
    "            n_neg = np.sum(y_train == 0)\n",
    "            pos_ratio=n_pos/(n_pos+n_neg)\n",
    "            \n",
    "            temp_ratio=pos_ratio*neg_pos_ratio\n",
    "            class_weightings={0:temp_ratio,1:1-temp_ratio}\n",
    "\n",
    "            logreg_w=LogisticRegression(max_iter=1000, class_weight=class_weightings)\n",
    "            logreg_w.fit(X_train, y_train)\n",
    "\n",
    "            #print('p_',end='')\n",
    "            #w_precision_temp=cross_val_score(logreg_w, X_tr_rs, y_tr_rs, cv=5, scoring=\"precision\")\n",
    "            #print('r_',end='')\n",
    "            #w_recall_temp=cross_val_score(logreg_w, X_tr_rs, y_tr_rs, cv=5, scoring=\"recall\")\n",
    "            #print('f_',end='')\n",
    "            #w_f1_temp=cross_val_score(logreg_w, X_tr_rs, y_tr_rs, cv=5, scoring=\"f1\")\n",
    "\n",
    "            #w_recall[neg_pos_ratio]=w_recall_temp\n",
    "            #w_precision[neg_pos_ratio]=w_precision_temp\n",
    "            #w_f1[neg_pos_ratio]=w_f1_temp\n",
    "            \n",
    "            logreg_w_preds=logreg_w.predict(X_val)\n",
    "            logreg_w_costs+=costs(y_val,logreg_w_preds)\n",
    "\n",
    "        w_cost[neg_pos_ratio]=logreg_w_costs/(attempt+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e5a7f797",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'w_cost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mk/f8dyn74n2kb1xh98q8xhy3d80000gn/T/ipykernel_65701/2281343383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw_cost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_cost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcost_min\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mw_cost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w_cost' is not defined"
     ]
    }
   ],
   "source": [
    "#print('Recall')\n",
    "#for item in w_recall:\n",
    "#    print (item, w_recall[item].mean())\n",
    "    \n",
    "#print('Precision')\n",
    "#for item in w_precision:\n",
    "#    print (item, w_precision[item].mean())\n",
    "\n",
    "#print('F1')\n",
    "#for item in w_f1:\n",
    "#    print (item, w_f1[item].mean())\n",
    "\n",
    "cost_min=99\n",
    "cost_idx=0\n",
    "\n",
    "print('Cost')\n",
    "for item in w_cost:\n",
    "    print (item, w_cost[item])\n",
    "    if cost_min>w_cost[item]:\n",
    "        cost_idx=item\n",
    "        cost_min=w_cost[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "44076608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best weighting is 90 at €0.0464/transaction with validation data (€0.0266 w/test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bce53384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055644387293578686"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, X_test, y_tr, y_test=train_test_split(Xy[0],Xy[1],test_size=0.2,random_state=hash(\"HEY EVERY! IT'S ME!\")%(2**32-1))\n",
    "X_train, X_val, y_train, y_val=train_test_split(X_tr,y_tr,test_size=0.25,random_state=hash(\"SPAMT    SPAMTON G. SPAMTON\")%(2**32-1))\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "pos_ratio=n_pos/(n_pos+n_neg)\n",
    "\n",
    "temp_ratio=pos_ratio*90\n",
    "class_weightings={0:temp_ratio,1:1-temp_ratio}\n",
    "logreg_w=LogisticRegression(max_iter=1000, class_weight=class_weightings)\n",
    "logreg_w.fit(X_train, y_train)\n",
    "logreg_w_preds=logreg_w.predict(X_test)\n",
    "costs(y_test,logreg_w_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad7f5a",
   "metadata": {},
   "source": [
    "### Attempt 3: Adjust Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c89d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "\n",
    "RERUN_TH_LOGREG=True\n",
    "\n",
    "\n",
    "if RERUN_TH_LOGREG:\n",
    "    th_recall={}\n",
    "    th_precision={}\n",
    "    th_f1={}\n",
    "\n",
    "    th_cost={}\n",
    "\n",
    "    #Don't think I can use validation here because there's no custom threshold for logreg\n",
    "    #THAT'S NOT VERY [[BIG SHOT]] OF YOU, [[SciKit]].\n",
    "    #but I'll randomize the train/holdout data and average it\n",
    "    #a lot\n",
    "    \n",
    "    for i in range(0,51):\n",
    "        th_cost[i]=[]\n",
    "        th_recall[i]=[]\n",
    "        th_precision[i]=[]\n",
    "        th_f1[i]=[]\n",
    "        \n",
    "    for attempt in range(0,10):\n",
    "        print(attempt,end='_')\n",
    "        X_train, X_test, y_train, y_test=train_test_split(Xy[0],Xy[1],test_size=0.2,random_state=hash(\"Chicken Dance\")%(2**32-1))\n",
    "        X_train, X_val, y_train, y_val=train_test_split(X_train,y_train,test_size=0.25,random_state=hash(\"Take On Me\")*attempt%(2**32-1))\n",
    "        \n",
    "        logreg_th=LogisticRegression(max_iter=1000)\n",
    "        logreg_th.fit(X_train, y_train)\n",
    "        \n",
    "        logreg_th_probs=logreg_th.predict_proba(X_val)\n",
    "        \n",
    "        for thresh in range(1,51):\n",
    "            logreg_th_preds = np.where(logreg_th_probs[:,1] > (thresh*0.01), 1, 0)\n",
    "            logreg_th_costs=costs(y_val,logreg_th_preds)\n",
    "            \n",
    "            scores=score(y_val,logreg_th_preds)\n",
    "            \n",
    "            th_recall[thresh].append(scores['recall'])\n",
    "            th_precision[thresh].append(scores['precision'])\n",
    "            th_f1[thresh].append(scores['f1'])\n",
    "            \n",
    "            th_cost[thresh].append(logreg_th_costs)\n",
    "    print('done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a111827d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'th_cost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mk/f8dyn74n2kb1xh98q8xhy3d80000gn/T/ipykernel_65701/445069482.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mth_cost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth_cost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Best threshold for cost: 20-30% (23% best) €0.0658/transaction (€0.0561 with validation data @ 21%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'th_cost' is not defined"
     ]
    }
   ],
   "source": [
    "for thresh in th_cost:\n",
    "    print(thresh,sum(th_cost[thresh])/10)\n",
    "    \n",
    "#Best threshold for cost: 20-30% (23% best) €0.0658/transaction (€0.0561 with validation data @ 21%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "29d5b69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0659366745172741"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_th=LogisticRegression(max_iter=1000)\n",
    "logreg_th.fit(X_train, y_train)\n",
    "logreg_th_probs=logreg_th.predict_proba(X_test)\n",
    "logreg_th_preds = np.where(logreg_th_probs[:,1] > 0.23, 1, 0)\n",
    "logreg_th_costs=costs(y_test,logreg_th_preds)\n",
    "logreg_th_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf73700",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Model Type 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa4789",
   "metadata": {},
   "source": [
    "### Baseline RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1cd7871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xy[0], Xy[1], test_size=0.2, random_state=hash(\"I CAN DO ANYTHING\")%(2**32))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=hash(\"CHAOS, CHAOS\")%(2**32))\n",
    "\n",
    "rf_oob = RandomForestRegressor(n_jobs=-1, max_features=3)\n",
    "rf_oob.fit(X_train,y_train)\n",
    "\n",
    "rf_oob_probs=rf_oob.predict(X_val)\n",
    "\n",
    "thresh=50\n",
    "rf_oob_preds=np.where(rf_oob_probs > (thresh*0.01), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bd5e2b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04035646159332551"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs(y_val,rf_oob_preds)\n",
    "# €0.0489\n",
    "# Ok that's actually really good for a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9766d",
   "metadata": {},
   "source": [
    "### Let's tune max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0033c750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,5,6,7,8,9,10,done\n",
      "CPU times: user 15min 39s, sys: 2 s, total: 15min 41s\n",
      "Wall time: 15min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Testing max_features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy[0], Xy[1], test_size=0.2, random_state=hash(\"I CAN DO ANYTHING\")%(2**32))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=hash(\"CHAOS, CHAOS\")%(2**32))\n",
    "\n",
    "probs={}\n",
    "\n",
    "for f in range(1,11):\n",
    "    print(f,end=',')\n",
    "    rf_f = RandomForestRegressor(max_features=f)\n",
    "    rf_f.fit(X_train,y_train)\n",
    "\n",
    "    rf_f_probs=rf_f.predict(X_val)\n",
    "    \n",
    "    probs[f]=rf_f_probs\n",
    "    \n",
    "    \n",
    "print('done')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "382176e7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.049836061515564786\n",
      "2 0.04174078540511632\n",
      "3 0.04025112821317734\n",
      "4 0.04035646159332551\n",
      "5 0.037482480589595746\n",
      "6 0.04035646159332551\n",
      "7 0.03886680440138655\n",
      "8 0.039077471161682885\n",
      "9 0.037587813969743915\n",
      "10 0.038972137781534716\n"
     ]
    }
   ],
   "source": [
    "for item in probs:\n",
    "    thresh=50\n",
    "    rf_f_preds=np.where(probs[item] > (thresh*0.01), True, False)\n",
    "    print(item,costs(y_val,rf_f_preds))\n",
    "    \n",
    "#Balancing time and cost: Let's stick with 3 features because after that it really doesn't seem to matter that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "28ce54a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=3)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_f = RandomForestRegressor(max_features=3)\n",
    "rf_f.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2aaf29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_temp=rf_f.predict(X_val)\n",
    "thresh_tuning=[]\n",
    "for thresh in range(0,26):\n",
    "    rf_f_preds=np.where(probs_temp > (thresh*0.01), True, False)\n",
    "    thresh_tuning.append(costs(y_val,rf_f_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "45b2a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best threshold is 0.18, with cost of €0.0385 with validation data (€0.0348 for test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fb64bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_temp=rf_f.predict(X_test)\n",
    "thresh_tuning1=[]\n",
    "for thresh in range(0,26):\n",
    "    rf_f_preds=np.where(probs_temp > (thresh*0.01), True, False)\n",
    "    thresh_tuning1.append(costs(y_test,rf_f_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "92e872b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9997191109862715,\n",
       " 'precision': 0.918918918918919,\n",
       " 'recall': 0.9357798165137615,\n",
       " 'f1': 0.9272727272727272}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(y_test,rf_f_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "608b8836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03054587166077713"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_tuning[18]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "99234f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03808450113075555"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_tuning1[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37359052",
   "metadata": {},
   "source": [
    "# Model Type 3: Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b4f99",
   "metadata": {},
   "source": [
    "### Almost-out-of-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e8d70f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Cost 0.03639916704838485\n",
      "Test Data Cost 0.04491577667942599\n"
     ]
    }
   ],
   "source": [
    "#Splitting data train-validation-test 60-20-20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy[0], Xy[1], test_size=0.2, random_state=hash(\"I Am Going To Touch The Cheese\")%(2**32))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=hash(\"Something About TerminalMontage\")%(2**32))\n",
    "\n",
    "#Modified code from XGB notebook\n",
    "gb_oob = xgb.XGBRegressor(random_state=hash(\"nope.avi\")%(2**32))\n",
    "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "\n",
    "gb_oob_fit = gb_oob.fit(X_train,y_train,eval_set=eval_set,verbose=False)\n",
    "\n",
    "gb_oob_proba=gb_oob.predict(X_val)\n",
    "gb_oob_preds=np.where(gb_oob_proba > 0.5, True, False)\n",
    "\n",
    "print(\"Validation Data Cost\",costs(y_val,gb_oob_preds))\n",
    "\n",
    "gb_oob_proba=gb_oob.predict(X_test)\n",
    "gb_oob_preds=np.where(gb_oob_proba > 0.5, True, False)\n",
    "print(\"Test Data Cost\",costs(y_test,gb_oob_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2169dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data Cost 0.03639916704838485\n",
    "# Test Data Cost 0.04491577667942599"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0e73b",
   "metadata": {},
   "source": [
    "### Not a bad baseline; let's improve on that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d4022c",
   "metadata": {},
   "source": [
    "### Attempt 1: Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0d49c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,done\n"
     ]
    }
   ],
   "source": [
    "gb_us_costs={}\n",
    "\n",
    "for pos_neg_ratio in range(0,150,10):\n",
    "    print(pos_neg_ratio,end=',')\n",
    "    n_pos = np.sum(y_train == 1)\n",
    "    sampling_ratio = {1 : n_pos, 0 : n_pos*pos_neg_ratio}\n",
    "\n",
    "    RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "    X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "    gb_us = xgb.XGBRegressor(random_state=hash(\"nope.avi\")%(2**32))\n",
    "    eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "    gb_us_fit = gb_us.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "    gb_us_proba=gb_us_fit.predict(X_val)\n",
    "    gb_us_preds=np.where(gb_us_proba > 0.5, True, False)\n",
    "\n",
    "    gb_us_costs[pos_neg_ratio]=costs(y_val,gb_us_preds)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b2bd407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04627012075148758"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "gb_us = xgb.XGBRegressor(random_state=hash(\"nope.avi\")%(2**32))\n",
    "eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "gb_us_fit = gb_us.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "gb_us_proba=gb_us_fit.predict(X_test)\n",
    "gb_us_preds=np.where(gb_us_proba > 0.5, True, False)\n",
    "\n",
    "costs(y_test,gb_us_preds)\n",
    "\n",
    "    \n",
    "#Above ratio 1:100, there isn't much difference so let's just use 1:80 for training it's just faster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9380853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 1.44 s, total: 23.7 s\n",
      "Wall time: 3.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04627012075148758"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "gb_us = xgb.XGBRegressor(random_state=hash(\"nope.avi\")%(2**32))\n",
    "eval_set = [(X_tr_rs, y_tr_rs), (X_test, y_test)]\n",
    "\n",
    "gb_us_fit = gb_us.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "gb_us_proba=gb_us_fit.predict(X_test)\n",
    "gb_us_preds=np.where(gb_us_proba > 0.5, True, False)\n",
    "\n",
    "costs(y_test,gb_us_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best ratio 1:80 @ €0.0463/transaction in test data; €0.0381 for validation\n",
    "#Probably a bit much overfitting; we'll work on that next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ff9c4",
   "metadata": {},
   "source": [
    "### Attempt 2: General re-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946b2d4",
   "metadata": {},
   "source": [
    "##### Step 1 - Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "62b74162",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2_3_4_"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mk/f8dyn74n2kb1xh98q8xhy3d80000gn/T/ipykernel_65701/1893415626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0meval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr_rs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr_rs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mgb_t_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr_rs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr_rs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mgb_t_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgb_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mgb_t_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgb_t_proba\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1497\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "cost_t={}\n",
    "cost_tt={}\n",
    "\n",
    "for lr in range(1,31):\n",
    "    print(lr,end='_')\n",
    "    gb_t = xgb.XGBRegressor(\n",
    "        #max_depth=7,\n",
    "        learning_rate=lr*0.01,\n",
    "        #subsample=0.8,\n",
    "        #min_child_weight=12,\n",
    "        #colsample_bytree=.7,\n",
    "        random_state=hash(\"nope.avi\")%(2**32))\n",
    "\n",
    "    eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "    gb_t_fit = gb_t.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "    gb_t_proba=gb_t.predict(X_val)\n",
    "    gb_t_preds=np.where(gb_t_proba > 0.5, True, False)\n",
    "    \n",
    "    gb_tt_proba=gb_t.predict(X_test)\n",
    "    gb_tt_preds=np.where(gb_tt_proba > 0.5, True, False)\n",
    "    \n",
    "    cost_t[lr]=costs(y_val,gb_t_preds)\n",
    "    cost_tt[lr]=costs(y_test,gb_tt_preds)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99863e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in cost_t:\n",
    "#    print(i,cost_t[i])\n",
    "    \n",
    "#0.1 appears to be the best learning_rate in general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeed28e",
   "metadata": {},
   "source": [
    "##### Step 2 - max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "cost_t={}\n",
    "cost_tt={}\n",
    "\n",
    "for md in range(1,11):\n",
    "    print(md,end='_')\n",
    "    gb_t = xgb.XGBRegressor(\n",
    "        max_depth=md,\n",
    "        learning_rate=0.1,\n",
    "        #subsample=0.1,\n",
    "        #min_child_weight=12,\n",
    "        #colsample_bytree=.7,\n",
    "        random_state=hash(\"nope.avi\")%(2**32))\n",
    "\n",
    "\n",
    "    eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "    gb_t_fit = gb_t.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "    gb_t_proba=gb_t.predict(X_val)\n",
    "    gb_t_preds=np.where(gb_t_proba > 0.5, True, False)\n",
    "    \n",
    "    gb_tt_proba=gb_t.predict(X_test)\n",
    "    gb_tt_preds=np.where(gb_tt_proba > 0.5, True, False)\n",
    "    \n",
    "    cost_t[md]=costs(y_val,gb_t_preds)\n",
    "    cost_tt[md]=costs(y_test,gb_tt_preds)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2a6b9c57",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.042989796097029735\n",
      "2 0.03745250084986654\n",
      "3 0.03638417717852024\n",
      "4 0.036594843938816575\n",
      "5 0.0347891866064331\n",
      "6 0.036700177318964744\n",
      "7 0.03712151083955742\n",
      "8 0.03701617745940925\n",
      "9 0.03976983521312625\n",
      "10 0.040206158603583536\n",
      "11 0.0386111680314964\n",
      "12 0.04273415972713959\n",
      "13 0.0399954918432872\n",
      "14 0.040191168733718925\n",
      "15 0.040206158603583536\n",
      "16 0.04062749212417621\n",
      "17 0.042418159586695085\n",
      "18 0.040296502113867094\n",
      "19 0.04157549254550973\n",
      "20 0.041364825785213395\n",
      "21 0.041259492405065226\n",
      "22 0.0416808259256579\n",
      "23 0.04115415902491706\n",
      "24 0.04157549254550973\n",
      "25 0.041364825785213395\n",
      "26 0.041259492405065226\n",
      "27 0.041259492405065226\n",
      "28 0.041259492405065226\n",
      "29 0.041259492405065226\n",
      "30 0.041259492405065226\n",
      "31 0.041259492405065226\n",
      "32 0.041259492405065226\n",
      "33 0.041259492405065226\n",
      "34 0.041259492405065226\n",
      "35 0.041259492405065226\n",
      "36 0.041259492405065226\n",
      "37 0.041259492405065226\n",
      "38 0.041259492405065226\n",
      "39 0.041259492405065226\n",
      "40 0.041259492405065226\n",
      "41 0.041259492405065226\n",
      "42 0.041259492405065226\n",
      "43 0.041259492405065226\n",
      "44 0.041259492405065226\n",
      "45 0.041259492405065226\n",
      "46 0.041259492405065226\n",
      "47 0.041259492405065226\n",
      "48 0.041259492405065226\n",
      "49 0.041259492405065226\n",
      "50 0.041259492405065226\n"
     ]
    }
   ],
   "source": [
    "for i in cost_t:\n",
    "    print(i,cost_t[i])\n",
    "#5 is best max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e5701",
   "metadata": {},
   "source": [
    "##### Step 3 - min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8577c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_4_6_8_10_12_14_16_18_20_22_24_26_28_30_32_34_36_38_40_42_44_46_48_50_done\n"
     ]
    }
   ],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "cost_t={}\n",
    "cost_tt={}\n",
    "\n",
    "for mcw in range(2,52,2):\n",
    "    print(mcw,end='_')\n",
    "    gb_t = xgb.XGBRegressor(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        #subsample=0.1,\n",
    "        min_child_weight=mcw,\n",
    "        #colsample_bytree=.7,\n",
    "        random_state=hash(\"nope.avi\")%(2**32))\n",
    "    \n",
    "    eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "    gb_t_fit = gb_t.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "    gb_t_proba=gb_t.predict(X_val)\n",
    "    gb_t_preds=np.where(gb_t_proba > 0.5, True, False)\n",
    "    \n",
    "    gb_tt_proba=gb_t.predict(X_test)\n",
    "    gb_tt_preds=np.where(gb_tt_proba > 0.5, True, False)\n",
    "    \n",
    "    cost_t[mcw]=costs(y_val,gb_t_preds)\n",
    "    cost_tt[mcw]=costs(y_test,gb_tt_preds)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0ad8c3f1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.0347891866064331\n",
      "4 0.033615529554938635\n",
      "6 0.033510196174790466\n",
      "8 0.03329952941449413\n",
      "10 0.0334048627946423\n",
      "12 0.03489451998658127\n",
      "14 0.0361735104182239\n",
      "16 0.03606817703807573\n",
      "18 0.0361735104182239\n",
      "20 0.033615529554938635\n",
      "22 0.033720862935086804\n",
      "24 0.033720862935086804\n",
      "26 0.033615529554938635\n",
      "28 0.0334048627946423\n",
      "30 0.033615529554938635\n",
      "32 0.033615529554938635\n",
      "34 0.033510196174790466\n",
      "36 0.033510196174790466\n",
      "38 0.033615529554938635\n",
      "40 0.033720862935086804\n",
      "42 0.03329952941449413\n",
      "44 0.033615529554938635\n",
      "46 0.033510196174790466\n",
      "48 0.033720862935086804\n",
      "50 0.033720862935086804\n"
     ]
    }
   ],
   "source": [
    "for i in cost_t:\n",
    "    print(i,cost_t[i])\n",
    "#>20 is best min_child_weight. Doesn't seem to increase past that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f25781",
   "metadata": {},
   "source": [
    "##### Step 4 -colsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f3ad195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_4_6_8_10_12_14_16_18_20_22_24_26_28_30_32_34_36_38_40_42_44_46_48_50_52_54_56_58_60_62_64_66_68_70_72_74_76_78_80_82_84_86_88_90_92_94_96_98_100_done\n"
     ]
    }
   ],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "cost_t={}\n",
    "cost_tt={}\n",
    "\n",
    "for ct in range(2,102,2):\n",
    "    print(ct,end='_')\n",
    "    gb_t = xgb.XGBRegressor(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        #subsample=0.1,\n",
    "        min_child_weight=20,\n",
    "        colsample_bytree=ct*0.01,\n",
    "        random_state=hash(\"nope.avi\")%(2**32))\n",
    "    \n",
    "    eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "    gb_t_fit = gb_t.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "    gb_t_proba=gb_t.predict(X_val)\n",
    "    gb_t_preds=np.where(gb_t_proba > 0.5, True, False)\n",
    "    \n",
    "    gb_tt_proba=gb_t.predict(X_test)\n",
    "    gb_tt_preds=np.where(gb_tt_proba > 0.5, True, False)\n",
    "    \n",
    "    cost_t[ct]=costs(y_val,gb_t_preds)\n",
    "    cost_tt[ct]=costs(y_test,gb_tt_preds)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "61c6e06c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.06249065271211374\n",
      "4 0.06249065271211374\n",
      "6 0.06249065271211374\n",
      "8 0.046510767251513124\n",
      "10 0.03841549114106466\n",
      "12 0.03841549114106466\n",
      "14 0.03692583394912569\n",
      "16 0.03692583394912569\n",
      "18 0.03426251970569225\n",
      "20 0.03734716746971837\n",
      "22 0.03734716746971837\n",
      "24 0.03457851984613676\n",
      "26 0.03457851984613676\n",
      "28 0.03457851984613676\n",
      "30 0.03287819589390145\n",
      "32 0.03287819589390145\n",
      "34 0.03436785308584042\n",
      "36 0.03436785308584042\n",
      "38 0.03319419603434596\n",
      "40 0.03329952941449413\n",
      "42 0.03329952941449413\n",
      "44 0.0334048627946423\n",
      "46 0.0334048627946423\n",
      "48 0.0334048627946423\n",
      "50 0.033615529554938635\n",
      "52 0.033615529554938635\n",
      "54 0.033510196174790466\n",
      "56 0.033510196174790466\n",
      "58 0.033510196174790466\n",
      "60 0.033510196174790466\n",
      "62 0.033510196174790466\n",
      "64 0.033510196174790466\n",
      "66 0.033510196174790466\n",
      "68 0.0334048627946423\n",
      "70 0.0334048627946423\n",
      "72 0.0334048627946423\n",
      "74 0.033510196174790466\n",
      "76 0.033510196174790466\n",
      "78 0.033510196174790466\n",
      "80 0.033510196174790466\n",
      "82 0.033510196174790466\n",
      "84 0.033510196174790466\n",
      "86 0.033510196174790466\n",
      "88 0.0334048627946423\n",
      "90 0.033510196174790466\n",
      "92 0.033510196174790466\n",
      "94 0.0334048627946423\n",
      "96 0.0334048627946423\n",
      "98 0.03489451998658127\n",
      "100 0.033615529554938635\n"
     ]
    }
   ],
   "source": [
    "for i in cost_t:\n",
    "    print(i,cost_t[i])\n",
    "#>.30 is best colsample. Doesn't seem to increase past that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afec934e",
   "metadata": {},
   "source": [
    "##### Step 5: Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d6c4903f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_10_15_20_25_30_35_40_45_50_55_60_65_70_75_80_85_90_95_100_done\n"
     ]
    }
   ],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "cost_t={}\n",
    "cost_tt={}\n",
    "\n",
    "for ss in range(5,105,5):\n",
    "    print(ss,end='_')\n",
    "    gb_t = xgb.XGBRegressor(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        subsample=ss*0.01,\n",
    "        min_child_weight=20,\n",
    "        colsample_bytree=0.3,\n",
    "        random_state=hash(\"nope.avi\")%(2**32))\n",
    "\n",
    "    \n",
    "    eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "    gb_t_fit = gb_t.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "    gb_t_proba=gb_t.predict(X_val)\n",
    "    gb_t_preds=np.where(gb_t_proba > 0.5, True, False)\n",
    "    \n",
    "    gb_tt_proba=gb_t.predict(X_test)\n",
    "    gb_tt_preds=np.where(gb_tt_proba > 0.5, True, False)\n",
    "    \n",
    "    cost_t[ss]=costs(y_val,gb_t_preds)\n",
    "    cost_tt[ss]=costs(y_test,gb_tt_preds)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cff9f3ac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.047684424303007594\n",
      "10 0.0438474530080797\n",
      "15 0.0438474530080797\n",
      "20 0.041289472144794434\n",
      "25 0.03606817703807573\n",
      "30 0.0347891866064331\n",
      "35 0.03319419603434596\n",
      "40 0.03319419603434596\n",
      "45 0.03319419603434596\n",
      "50 0.03606817703807573\n",
      "55 0.03468385322628493\n",
      "60 0.03468385322628493\n",
      "65 0.03606817703807573\n",
      "70 0.03596284365792756\n",
      "75 0.03596284365792756\n",
      "80 0.03308886265419779\n",
      "85 0.03447318646598859\n",
      "90 0.0334048627946423\n",
      "95 0.0334048627946423\n",
      "100 0.03287819589390145\n",
      "5 0.039905148333003626\n",
      "10 0.04150013890509077\n",
      "15 0.042884462716881566\n",
      "20 0.04171080566538711\n",
      "25 0.039258158182250015\n",
      "30 0.03957415832269452\n",
      "35 0.03957415832269452\n",
      "40 0.039363491562398184\n",
      "45 0.03978482508299086\n",
      "50 0.039363491562398184\n",
      "55 0.03978482508299086\n",
      "60 0.03957415832269452\n",
      "65 0.040958482134485316\n",
      "70 0.03967949170284269\n",
      "75 0.03808450113075555\n",
      "80 0.03946882494254635\n",
      "85 0.039363491562398184\n",
      "90 0.04074781537418898\n",
      "95 0.03967949170284269\n",
      "100 0.039258158182250015\n"
     ]
    }
   ],
   "source": [
    "for i in cost_t:\n",
    "    print(i,cost_t[i])\n",
    "    \n",
    "for i in cost_tt:\n",
    "    print(i,cost_tt[i])\n",
    "#~.40 appears to be best subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "94ebe834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28_30_32_34_36_38_40_42_44_46_48_50_done\n"
     ]
    }
   ],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "RUS=imblearn.under_sampling.RandomUnderSampler(sampling_strategy = sampling_ratio, random_state=(hash(\"haha python go b+r*10\"))%(2**32))\n",
    "X_tr_rs, y_tr_rs = RUS.fit_resample(X_train, y_train)\n",
    "\n",
    "cost_t={}\n",
    "cost_tt={}\n",
    "\n",
    "for thresh in range(28,52,2):\n",
    "    print(thresh,end='_')\n",
    "    gb_t = xgb.XGBRegressor(\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.45,\n",
    "        min_child_weight=20,\n",
    "        colsample_bytree=.25,\n",
    "        random_state=hash(\"nope.avi\")%(2**32))\n",
    "\n",
    "    n_pos = np.sum(y_train == 1)\n",
    "    n_neg = np.sum(y_train == 0)\n",
    "    sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "    \n",
    "    eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "    gb_t_fit = gb_t.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "    gb_t_proba=gb_t.predict(X_val)\n",
    "    gb_t_preds=np.where(gb_t_proba > thresh*0.01, True, False)\n",
    "    \n",
    "    gb_tt_proba=gb_t.predict(X_test)\n",
    "    gb_tt_preds=np.where(gb_tt_proba > thresh*0.01, True, False)\n",
    "    \n",
    "    cost_t[thresh]=costs(y_val,gb_t_preds)\n",
    "    cost_tt[thresh]=costs(y_test,gb_tt_preds)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "05f70a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 -0.004875315226544975\n",
      "30 -0.004664648466248637\n",
      "32 -0.006259639038335783\n",
      "34 -0.006364972418483952\n",
      "36 -0.006470305798632121\n",
      "38 -0.00657563917878029\n",
      "40 -0.00657563917878029\n",
      "42 -0.006470305798632121\n",
      "44 -0.00657563917878029\n",
      "46 -0.009238953422213723\n",
      "48 -0.009028286661917392\n",
      "50 -0.010412610473708186\n"
     ]
    }
   ],
   "source": [
    "for i in cost_t:\n",
    "    print(i,cost_t[i]-cost_tt[i])\n",
    "\n",
    "#cost_tt\n",
    "#>0.38 thresh seems to have the best val/test cost of 0.0327/0.0363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c7899409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{28: 0.0381598547711745,\n",
       " 30: 0.03773852125058182,\n",
       " 32: 0.038806844921928124,\n",
       " 34: 0.038701511541779955,\n",
       " 36: 0.03849084478148362,\n",
       " 38: 0.03828017802118728,\n",
       " 40: 0.03828017802118728,\n",
       " 42: 0.03934850169253357,\n",
       " 44: 0.039137834932237235,\n",
       " 46: 0.04180114917567067,\n",
       " 48: 0.04297480622716514,\n",
       " 50: 0.044148463278659594}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0b255804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9990344440153085,\n",
       " 'precision': 0.7045454545454546,\n",
       " 'recall': 0.8532110091743119,\n",
       " 'f1': 0.7717842323651453}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_t = xgb.XGBRegressor(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.45,\n",
    "    min_child_weight=20,\n",
    "    colsample_bytree=.25,\n",
    "    random_state=hash(\"nope.avi\")%(2**32))\n",
    "\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "sampling_ratio = {1 : n_pos, 0 : n_pos*80}\n",
    "\n",
    "eval_set = [(X_tr_rs, y_tr_rs), (X_val, y_val)]\n",
    "\n",
    "gb_t_fit = gb_t.fit(X_tr_rs,y_tr_rs,eval_set=eval_set, verbose=False)\n",
    "gb_t_proba=gb_t.predict(X_val)\n",
    "gb_t_preds=np.where(gb_t_proba > 0.30, True, False)\n",
    "\n",
    "gb_tt_proba=gb_t.predict(X_test)\n",
    "gb_tt_preds=np.where(gb_tt_proba > 0.30, True, False)\n",
    "\n",
    "cost_t=costs(y_val,gb_t_preds)\n",
    "cost_tt=costs(y_test,gb_tt_preds)\n",
    "\n",
    "score(y_test,gb_tt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5f8a25d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03817484464103911"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2c137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
